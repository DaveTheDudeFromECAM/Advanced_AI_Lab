{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File descriptions\n",
    "\n",
    "# train_val2019 - Contains the training and validation images in a directory structure following {iconic category name}/{category name}/{image id}.jpg .\n",
    "# train2019.json - Contains the training annotations.\n",
    "# val2019.json - Contains the validation annotations.\n",
    "# test2019 - Contains a single directory of test images.\n",
    "# test2019.json - Contains test image information.\n",
    "# kaggle_sample_submission.csv - A sample submission file in the correct format.\n",
    "\n",
    "# knowing thaht this is the structure of the input folder\n",
    "# Show me the first 5 images of class 2 \n",
    "\n",
    "# import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set the path\n",
    "path = \"input\"\n",
    "train_path = os.path.join(path, \"train_val2019\")\n",
    "test_path = os.path.join(path, \"test2019\")\n",
    "train_json = os.path.join(path, \"train2019.json\")\n",
    "test_json = os.path.join(path, \"test2019.json\")\n",
    "\n",
    "# read the json file\n",
    "with open(train_json) as f:\n",
    "    train_data = json.load(f)\n",
    "with open(test_json) as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# convert the json file to dataframe\n",
    "train_df = pd.DataFrame(train_data['annotations'])\n",
    "test_df = pd.DataFrame(test_data['images'])\n",
    "\n",
    "# merge the dataframes\n",
    "train_df = pd.merge(train_df, test_df, how='left', on='image_id')\n",
    "\n",
    "# rename the columns\n",
    "train_df.rename(columns={'image_id': 'id', 'category_id': 'label'}, inplace=True)\n",
    "\n",
    "# drop the unwanted columns\n",
    "train_df.drop(['iscrowd', 'bbox', 'area', 'id_y', 'license', 'date_captured'], axis=1, inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
